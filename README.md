## Рация, мост через волны

Проект был выполнен в ходе второго этапа Школы по практическому программированию и анализу данных на базе НИУ ВШЭ в Санкт-Петербурге (06.05.2024 - 11.05.2024)

Современные судебные процессы, медицинские консультации, учебные защиты и деловые встречи требуют точного и оперативного документирования устной речи. Ручная стенография и диктовка отнимают много времени и ресурсов, а наше аппаратно‑программное решение позволяет автоматизировать запись и анализ аудио.

Проект состоит из двух модулей на базе Arduino: передающего с микрофоном MAX9814 и шифрованием, а также приёмного с радиомодулем NRF24L01, передающего данные на сервер по USB. На сервере Python‑скрипт восстанавливает недостающие сэмплы методом линейной экстраполяции до 44,1 кГц, сохраняет .wav и преобразует аудио в текст, используя Google API (также реализовано использование CMUSphinx<sup>[1](#myfootnote)</sup>)

Предложенная система пригодится в судах для автоматической стенографии, в полиции для записи допросов, в медицине для фиксации консультаций, в образовании для документирования защит проектов и в бизнесе для анализа встреч и оценки эффективности.

В дальнейшем мы планируем усилить защиту данных более сложными алгоритмами шифрования, внедрить семантический анализ текста с помощью NLP‑моделей, улучшить качество аппаратной части и разработать локальную модель распознавания речи без зависимости от внешних сервисов.

Авторы проекта: Битлев Роберт, Бурдина Арина, Шиянов Александр

Наставники: Саратовцев Артём, Земцова Александра

---

<sup><a name="myfootnote">1</a></sup> использовались модели ([ссылка](https://sourceforge.net/projects/cmusphinx/files/Acoustic%20and%20Language%20Models/Russian/zero_ru_cont_8k_v3.tar.gz/download) на скачивание) 

Переименнованные файлы и папки:

|Тип| Исходное название|Новое название|
|:---|:---|:---|
|Папка|zero_ru_cont_8k_v3|ru-RU|
|Папка|zero_ru.cd_cont_4000|acoustic-model|
|Файл|ru.dic|language-model.lm.bin|
|Файл|ru.lm|pronounciation-dictionary.dict|

---

P.S. Перед запуском программы `recognize_pocketsphinx.py` рекомендуем скачать по [ссылке](https://1drv.ms/u/c/a320c9b39dd5bde2/Ec7xQSLZTJdKoTS4QTG0C7sB66h2HlNeFix8cKBPvGLXow) архив, в котором файлы уже переименованы, распаковать его в папку `RU-ru` (в этой папке должны лежать файлы `language-model.lm.bin`, `pronounciation-dictionary.dict` и папка `acoustic-model`). Далее:
1. Выполните
```sh
pip install -r requirements.txt
```

2. Зайдите в директорию `venv\Lib\site-packages\speech_recognition\pocketsphinx-data`, где `venv` - название виртуальной среды, замените его на Ваше название (в этой директории по умолчанию лежит папка `en-US`)

3. Скопируйте папку ru-RU и вставьте её в эту директорию
